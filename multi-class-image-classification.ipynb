{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Multiclass Classification","metadata":{}},{"cell_type":"markdown","source":"## Features\n\n1. Done by Gokulakannan S\n2. Multi class image classification Task\n3. Model Used: VGG Model\n4. Data present in Kaggle : https://www.kaggle.com/nadeemsk4347/classifying-flowers-with-keras/data . It is the same data provided to me by TMLC.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-26T10:20:21.334943Z","iopub.execute_input":"2021-10-26T10:20:21.335218Z","iopub.status.idle":"2021-10-26T10:20:21.377135Z","shell.execute_reply.started":"2021-10-26T10:20:21.335144Z","shell.execute_reply":"2021-10-26T10:20:21.376466Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#Importing the necessary Libraries\nimport os\nimport numpy as np\nimport scipy.io\nimport keras\nfrom keras.models import Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom sklearn.model_selection import train_test_split\nimport tarfile\nimport cv2\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.metrics import confusion_matrix\nfrom keras import Sequential\nfrom tensorflow.keras.applications import VGG19 #For Transfer Learning\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import SGD,Adam\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.layers import Flatten,Dense,BatchNormalization,Activation,Dropout\n","metadata":{"execution":{"iopub.status.busy":"2021-10-26T10:20:55.180455Z","iopub.execute_input":"2021-10-26T10:20:55.180710Z","iopub.status.idle":"2021-10-26T10:20:55.913329Z","shell.execute_reply.started":"2021-10-26T10:20:55.180681Z","shell.execute_reply":"2021-10-26T10:20:55.912615Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Step 1 : Processing Labels","metadata":{}},{"cell_type":"code","source":"img_labels = scipy.io.loadmat(\"/kaggle/input/flower-dataset-102/imagelabels.mat\")\nimg_labels = img_labels[\"labels\"]\nimg_labels = img_labels[0]\nfor i in range(len(img_labels)):\n  img_labels[i] = img_labels[i] - 1\nprint(img_labels)","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-10-26T10:20:59.066426Z","iopub.execute_input":"2021-10-26T10:20:59.067018Z","iopub.status.idle":"2021-10-26T10:20:59.115663Z","shell.execute_reply.started":"2021-10-26T10:20:59.066978Z","shell.execute_reply":"2021-10-26T10:20:59.114822Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Step 2 : Processing Images","metadata":{}},{"cell_type":"code","source":"# We are reducing the dimensions of the images to 50 X 50\nIMG_SIZE = 50\n\ntrain_x = []\ntrain_y = []\ntar = tarfile.open('/kaggle/input/flower-dataset-102/102flowers.tgz', \"r:gz\")\ni = 0\nfor tarinfo in tqdm(tar):\n    i+=1\n    tar.extract(tarinfo.name)\n    \n    if(tarinfo.name[-4:] == '.jpg'):\n        var = tarinfo.name[11:15]\n        img_num = int(var)-1\n        train_y.append(img_labels[img_num])\n        \n        image = cv2.imread(tarinfo.name)\n        resized = cv2.resize(image, (IMG_SIZE,IMG_SIZE))\n        normalized_img = cv2.normalize(resized, None, alpha=0, beta=1, \n                                norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n        train_x.append(normalized_img)\n\n#         label_list.append(tarinfo.name.split('_')[0])\n    if(tarinfo.isdir()):\n        os.rmdir(tarinfo.name)\n    else:\n        os.remove(tarinfo.name) \n\ntar.close()\ntrain_x = np.array(train_x)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T10:21:05.201401Z","iopub.execute_input":"2021-10-26T10:21:05.201657Z","iopub.status.idle":"2021-10-26T10:21:52.987522Z","shell.execute_reply.started":"2021-10-26T10:21:05.201628Z","shell.execute_reply":"2021-10-26T10:21:52.986608Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#Change the number in from 0 to 8189 to look into any image\nplt.imshow(train_x[8180])\nprint(train_x.shape)\nprint(\"The Label of this image is \",train_y[8180])","metadata":{"execution":{"iopub.status.busy":"2021-10-26T11:14:23.216177Z","iopub.execute_input":"2021-10-26T11:14:23.216719Z","iopub.status.idle":"2021-10-26T11:14:23.398774Z","shell.execute_reply.started":"2021-10-26T11:14:23.216680Z","shell.execute_reply":"2021-10-26T11:14:23.398094Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"## Step 3 : Data Validation (Train, Validation and Test split)","metadata":{}},{"cell_type":"code","source":"#training and test are split here\ntrainx, testx, trainy, testy = train_test_split(train_x, train_y, test_size=0.10, random_state=10)\n\ntrainx, valx, trainy, valy = train_test_split(trainx, trainy, test_size=0.15, random_state=10)\n\ntrainy = to_categorical(trainy)\ntesty = to_categorical(testy)\nvaly = to_categorical(valy)\nnp.save('testx.npy', testx)\nnp.save('testy.npy', testy)\n\nprint(\"Training data number:\",len(trainx))\nprint(\"Testing data number:\",len(testx))\nprint(\"Validation data number:\",len(valx))\n\nprint(\"Training labels number:\",len(trainy))\nprint(\"Testing labels number:\",len(testy))\nprint(\"Validation labels number:\",len(valy))","metadata":{"execution":{"iopub.status.busy":"2021-10-26T10:37:35.786427Z","iopub.execute_input":"2021-10-26T10:37:35.786682Z","iopub.status.idle":"2021-10-26T10:37:35.967288Z","shell.execute_reply.started":"2021-10-26T10:37:35.786653Z","shell.execute_reply":"2021-10-26T10:37:35.966510Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"print(\"Training data shape:\",trainx.shape)\nprint(\"Testing data shape:\",testx.shape)\nprint(\"Validation data shape:\",valx.shape)\n\nprint(\"Training labels shape:\",trainy.shape)\nprint(\"Testing labels shape:\",testy.shape)\nprint(\"Validation labels shape:\",valy.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T10:37:38.305432Z","iopub.execute_input":"2021-10-26T10:37:38.306071Z","iopub.status.idle":"2021-10-26T10:37:38.313759Z","shell.execute_reply.started":"2021-10-26T10:37:38.306031Z","shell.execute_reply":"2021-10-26T10:37:38.312753Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"## Step 4 : Model Building","metadata":{}},{"cell_type":"code","source":"# model 1\n# The model is creating taking the base model as VGG19\nbase_model = VGG19(include_top = False, weights = 'imagenet', input_shape = (50,50,3), classes = trainy.shape[1])","metadata":{"execution":{"iopub.status.busy":"2021-10-26T10:42:18.974720Z","iopub.execute_input":"2021-10-26T10:42:18.975263Z","iopub.status.idle":"2021-10-26T10:42:19.325652Z","shell.execute_reply.started":"2021-10-26T10:42:18.975225Z","shell.execute_reply":"2021-10-26T10:42:19.324926Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"#Creating extra depp nueral layers for transfer learning\nmodel= Sequential()\nmodel.add(base_model) \nmodel.add(Flatten()) ","metadata":{"execution":{"iopub.status.busy":"2021-10-26T10:42:20.415247Z","iopub.execute_input":"2021-10-26T10:42:20.415711Z","iopub.status.idle":"2021-10-26T10:42:20.481872Z","shell.execute_reply.started":"2021-10-26T10:42:20.415674Z","shell.execute_reply":"2021-10-26T10:42:20.481205Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-26T10:42:21.641065Z","iopub.execute_input":"2021-10-26T10:42:21.641630Z","iopub.status.idle":"2021-10-26T10:42:21.651514Z","shell.execute_reply.started":"2021-10-26T10:42:21.641590Z","shell.execute_reply":"2021-10-26T10:42:21.650660Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"#Adding the Dense layers along with activation and batch normalization\nmodel.add(Dense(1024,activation=('relu'),input_dim=512))\nmodel.add(Dense(512,activation=('relu'))) \nmodel.add(Dense(256,activation=('relu'))) \nmodel.add(Dropout(.3))\nmodel.add(Dense(128,activation=('relu')))\n#model.add(Dropout(.2))\nmodel.add(Dense(102,activation=('softmax'))) \n\n#Checking the final model summary\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-26T10:42:22.956580Z","iopub.execute_input":"2021-10-26T10:42:22.956980Z","iopub.status.idle":"2021-10-26T10:42:23.007299Z","shell.execute_reply.started":"2021-10-26T10:42:22.956946Z","shell.execute_reply":"2021-10-26T10:42:23.006534Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"#learning rate parameter to initialize the learning rate to the model\nlrr= ReduceLROnPlateau(monitor='val_acc', factor=.01, patience=3, min_lr=1e-5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Initializing the hyperparameters\nbatch_size= 100\nepochs=50\nlearn_rate=.001\nsgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\nadam=Adam(lr=learn_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\nmodel.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-10-26T10:42:23.945387Z","iopub.execute_input":"2021-10-26T10:42:23.945646Z","iopub.status.idle":"2021-10-26T10:42:23.957475Z","shell.execute_reply.started":"2021-10-26T10:42:23.945616Z","shell.execute_reply":"2021-10-26T10:42:23.956715Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"#fitting the first model\nmodel.fit(trainx, trainy, validation_data = (valx, valy), epochs=60, batch_size=20)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T10:42:25.397354Z","iopub.execute_input":"2021-10-26T10:42:25.397737Z","iopub.status.idle":"2021-10-26T10:51:48.432004Z","shell.execute_reply.started":"2021-10-26T10:42:25.397703Z","shell.execute_reply":"2021-10-26T10:51:48.431147Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"### Here we get the maximum accuracy to be 99% but the validation accuracy is 79%(maximum)","metadata":{}},{"cell_type":"code","source":"# model2\n# The model is basically the same but the we are using data augmentation technique to increase the number of datasets.\nbase_model = VGG19(include_top = False, weights = 'imagenet', input_shape = (50,50,3), classes = trainy.shape[1])\nmodel.add(base_model) \nmodel.add(Flatten())\n#Adding the Dense layers along with activation and batch normalization\nmodel.add(Dense(1024,activation=('relu'),input_dim=512))\nmodel.add(Dense(512,activation=('relu'))) \nmodel.add(Dense(256,activation=('relu'))) \nmodel.add(Dropout(.3))\nmodel.add(Dense(128,activation=('relu')))\n#model.add(Dropout(.2))\nmodel.add(Dense(102,activation=('softmax'))) \n\n#Checking the final model summary\nmodel.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-26T11:22:05.327285Z","iopub.execute_input":"2021-10-26T11:22:05.328102Z","iopub.status.idle":"2021-10-26T11:22:05.340833Z","shell.execute_reply.started":"2021-10-26T11:22:05.328061Z","shell.execute_reply":"2021-10-26T11:22:05.340139Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"#Initializing the hyperparameters\nbatch_size= 100\nepochs=50\nlearn_rate=.001\nsgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\nadam=Adam(lr=learn_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\nmodel.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True, zoom_range=.1)\n\nval_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True, zoom_range=.1)\n\ntest_generator = ImageDataGenerator(rotation_range=2, horizontal_flip= True, zoom_range=.1)\n\n#Fitting the augmentation defined above to the data\ntrain_generator.fit(trainx)\nval_generator.fit(valx)\ntest_generator.fit(testx)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T10:58:33.226356Z","iopub.execute_input":"2021-10-26T10:58:33.226615Z","iopub.status.idle":"2021-10-26T10:58:33.314137Z","shell.execute_reply.started":"2021-10-26T10:58:33.226586Z","shell.execute_reply":"2021-10-26T10:58:33.313370Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"model.fit_generator(train_generator.flow(trainx, trainy, batch_size= batch_size),epochs = epochs, steps_per_epoch = trainx.shape[0]//batch_size, validation_data = val_generator.flow(valx, valy, batch_size = batch_size), validation_steps = 250, callbacks=[lrr], verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T10:59:33.826296Z","iopub.execute_input":"2021-10-26T10:59:33.826973Z","iopub.status.idle":"2021-10-26T11:06:14.289425Z","shell.execute_reply.started":"2021-10-26T10:59:33.826934Z","shell.execute_reply":"2021-10-26T11:06:14.288747Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"model.save('vgg_trnsfer_learning_102_model_2.h5')","metadata":{"execution":{"iopub.status.busy":"2021-10-26T11:07:44.404629Z","iopub.execute_input":"2021-10-26T11:07:44.404987Z","iopub.status.idle":"2021-10-26T11:07:44.677190Z","shell.execute_reply.started":"2021-10-26T11:07:44.404951Z","shell.execute_reply":"2021-10-26T11:07:44.676379Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"### Here we get the maximum accuracy to be 99.94%","metadata":{}},{"cell_type":"markdown","source":"## Step 5 : Testing the model","metadata":{}},{"cell_type":"code","source":"# Model 1 Testing\nfrom keras.models import load_model\nmodel = load_model(\"vgg_transfer_learning_102_model.h5\")\n\nscore = model.evaluate(testx, testy)\n\nprint('Test loss:', score[0]) \nprint('Test accuracy:', score[1])\n\n#Predict output on sample input data\npred = model.predict(testx) \npred = np.argmax(pred, axis = 1)[:10] \nlabel = np.argmax(testy,axis = 1)[:10] \n\nprint(\"Predicted labels:\",pred) \nprint(\"Actual Labels:   \",label)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T10:52:11.791234Z","iopub.execute_input":"2021-10-26T10:52:11.791932Z","iopub.status.idle":"2021-10-26T10:52:13.569410Z","shell.execute_reply.started":"2021-10-26T10:52:11.791868Z","shell.execute_reply":"2021-10-26T10:52:13.568671Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"#Model 2 Testing\n\nfrom keras.models import load_model\nmodel = load_model(\"vgg_transfer_learning_102_model_2.h5\")\n\nscore = model.evaluate(testx, testy)\n\nprint('Test loss:', score[0]) \nprint('Test accuracy:', score[1])\n\n#Predict output on sample input data\npred = model.predict(testx) \npred = np.argmax(pred, axis = 1)[:10] \nlabel = np.argmax(testy,axis = 1)[:10] \n\nprint(\"Predicted labels:\",pred) \nprint(\"Actual Labels:   \",label)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T11:07:50.307809Z","iopub.execute_input":"2021-10-26T11:07:50.308129Z","iopub.status.idle":"2021-10-26T11:07:51.768468Z","shell.execute_reply.started":"2021-10-26T11:07:50.308088Z","shell.execute_reply":"2021-10-26T11:07:51.767566Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion","metadata":{}},{"cell_type":"markdown","source":"### Hence the second model seems to perform well with an accuracy of 78.63% and the model 1 has an accuracy of 73.01% on the test data. This implies that the model performs well upon data augmentation. Further accuracy can be increased by introducing better architectures like MobileNet or ResNet.","metadata":{}},{"cell_type":"markdown","source":"# Refrences","metadata":{}},{"cell_type":"markdown","source":"1. https://analyticsindiamag.com/transfer-learning-for-multi-class-image-classification-using-deep-convolutional-neural-network/\n2. https://www.kaggle.com/nadeemsk4347/classifying-flowers-with-keras\n\n\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}